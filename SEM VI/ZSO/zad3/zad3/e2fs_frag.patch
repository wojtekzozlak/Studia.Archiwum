From c06fc4ebee5c76e8b35a82b66f437d554568bfe0 Mon Sep 17 00:00:00 2001
From: Wojciech Zoltak <wz292583@students.mimuw.edu.pl>
Date: Wed, 27 Jun 2012 12:56:07 +0200
Subject: [PATCH] Zero block device.

---
 drivers/block/Kconfig     |   15 ++
 drivers/block/Makefile    |    1 +
 drivers/block/zero_bdev.c |  505 +++++++++++++++++++++++++++++++++++++++++++++
 fs/ext2/ext2.h            |    6 +
 fs/ext2/ioctl.c           |   57 +++++-
 include/linux/ext2_fs.h   |    1 +
 6 files changed, 584 insertions(+), 1 deletions(-)
 create mode 100644 drivers/block/zero_bdev.c

diff --git a/drivers/block/Kconfig b/drivers/block/Kconfig
index 77bfce5..473a47c 100644
--- a/drivers/block/Kconfig
+++ b/drivers/block/Kconfig
@@ -15,6 +15,21 @@ menuconfig BLK_DEV
 
 if BLK_DEV
 
+config ZERO_BDEV
+	tristate "Zero block disk support"
+	---help---
+	  Device similiar to the ram disk. Holds a disc data in a memory,
+	  but only a non-empty blocks. May be used to simulate metadata
+	  defragmentation on very big discs.
+	
+config ZERO_BDEV_COUNT
+	int "Default number of zbd disks"
+	default "4"
+	depends on ZERO_BDEV
+	help
+	  The default value is 4 zbd disks.
+
+
 config BLK_DEV_FD
 	tristate "Normal floppy disk support"
 	depends on ARCH_MAY_HAVE_PC_FDC
diff --git a/drivers/block/Makefile b/drivers/block/Makefile
index aff5ac9..73aa4c0 100644
--- a/drivers/block/Makefile
+++ b/drivers/block/Makefile
@@ -5,6 +5,7 @@
 # Rewritten to use lists instead of if-statements.
 # 
 
+obj-$(CONFIG_ZERO_BDEV)		+= zero_bdev.o
 obj-$(CONFIG_MAC_FLOPPY)	+= swim3.o
 obj-$(CONFIG_BLK_DEV_SWIM)	+= swim_mod.o
 obj-$(CONFIG_BLK_DEV_FD)	+= floppy.o
diff --git a/drivers/block/zero_bdev.c b/drivers/block/zero_bdev.c
new file mode 100644
index 0000000..2458283
--- /dev/null
+++ b/drivers/block/zero_bdev.c
@@ -0,0 +1,505 @@
+/* Wojciech Żółtak (wz292583) - Zero Blocks device
+ *
+ * Device is mainly based on a `brd.c` ram drive implementation. */
+
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+
+#include <linux/kernel.h> /* printk() */
+#include <linux/fs.h>     /* everything... */
+#include <linux/errno.h>  /* error codes */
+#include <linux/types.h>  /* size_t */
+#include <linux/vmalloc.h>
+#include <linux/genhd.h>
+#include <linux/blkdev.h>
+#include <linux/hdreg.h>
+#include <linux/gfp.h>
+#include <linux/slab.h>
+#include <linux/radix-tree.h>
+
+#define SECTOR_SHIFT 9
+#define ZERO_BDEV_CONFIGURE 0x66660667
+
+#define ZB_INACTIVE 0
+#define ZB_ACTIVE   1
+#define ZB_REMOVED  2
+
+#ifndef CONFIG_ZERO_BDEV_COUNT
+  #define CONFIG_ZERO_BDEV_COUNT 4
+#endif
+
+MODULE_LICENSE("GPL");
+
+static int num_devs = 0;
+module_param(num_devs, int, 0);
+
+static DEFINE_MUTEX(devices_mutex);
+
+struct zero_bdev_config_arg
+{
+  uint32_t zbc_block_size;
+  uint32_t zbc_pad_; //unused
+  uint64_t zbc_num_blocks;
+};
+
+/* main zb device structure */
+static struct zb_device {
+  char zb_status;
+  char zb_name[16];
+  long zb_block_size;
+  int  zb_block_shift; /* log_2(zb_block_size) */
+  long zb_num_blocks;
+  int  zb_minor;
+  int  zb_major;
+
+  struct radix_tree_root zb_data;
+  struct rw_semaphore zb_sem;
+
+  struct gendisk *zb_gd;
+  struct request_queue *zb_queue;
+} *devices;
+
+/* single data block */
+struct data_block {
+  char *data;
+  unsigned long ix;
+};
+
+static int
+copy_from_zerod(void *dst, struct zb_device *dev,
+                sector_t sector, uint32_t n)
+/* Copy `n` bytes from zbd starting from sector `sector`. */
+{
+  uint32_t offset;
+  uint64_t ix, buff;
+  size_t copy;
+  struct data_block* block;
+
+  while (n > 0) {
+    buff = sector << SECTOR_SHIFT;
+    ix = buff >> dev->zb_block_shift;
+
+    /* every request should be properly aligned */
+    offset = buff - (ix * dev->zb_block_size);
+    if (offset != 0) {
+      printk (KERN_WARNING "%s: bad aligned request\n", dev->zb_name);
+      return -EINVAL;
+    }
+
+    copy = min_t(size_t, dev->zb_block_size, n);
+    rcu_read_lock();
+    block = radix_tree_lookup(&dev->zb_data, ix);
+    rcu_read_unlock();
+
+    if (block) {
+      memcpy(dst, block->data + offset, copy);
+    } else {
+      memset(dst, 0, copy);
+    }
+
+    n -= copy;
+    dst += copy;
+    sector += copy >> SECTOR_SHIFT;
+  }
+
+  return 0;
+}
+
+static int
+check_zero(char *dst, uint32_t n)
+/* Returns 1 if `n` bytes starting from `dst` are all zeros. */
+{
+  if (n == 0)
+    return 1;
+  if (dst[0] == 0 && memcmp(dst, dst + 1, n - 1) == 0)
+    return 1;
+  return 0;
+}
+
+static struct data_block*
+alloc_block(struct zb_device *dev, uint64_t ix)
+/* Returns a pointer to a new, empty data_block. */
+{
+  struct data_block *block = kzalloc(sizeof(struct data_block) + dev->zb_block_size,
+                                     GFP_NOIO);
+  block->data = ((void *) block) + sizeof(struct data_block);
+  block->ix = (unsigned long) ix;
+  if (!block)
+    return NULL;
+
+  if (radix_tree_preload(GFP_NOIO)) {
+    kfree(block);
+    return NULL;
+  }
+
+  if (radix_tree_insert(&dev->zb_data, ix, block)) {
+    kfree(block);
+    block = radix_tree_lookup(&dev->zb_data, ix);
+    BUG_ON(!block);
+  }
+  radix_tree_preload_end();
+
+  return block;
+}
+
+#define FREE_BATCH 16
+void
+cleanup_tree(struct zb_device *dev)
+/* Removes all data from the radix tree. */
+{
+  unsigned long pos = 0;
+  struct data_block *blocks[FREE_BATCH];
+  int nr_pages;
+
+  do {
+    int i;
+    nr_pages = radix_tree_gang_lookup(&dev->zb_data, (void **)blocks,
+                                      pos, FREE_BATCH);
+
+    for (i = 0; i < nr_pages; i++) {
+      struct data_block *ret;
+      BUG_ON(blocks[i]->ix < pos);
+      pos = blocks[i]->ix;
+      ret = radix_tree_delete(&dev->zb_data, pos);
+      BUG_ON(!ret || ret != blocks[i]);
+      kfree(blocks[i]);
+
+    }
+    pos++;
+  } while(nr_pages > 0);
+}
+
+static int
+copy_to_zerod(struct zb_device *dev, void *src,
+              sector_t sector, uint32_t n)
+/* Copy `n` bytes from userspace into zbd, starting from `sector`. */
+{
+  uint32_t offset;
+  uint64_t ix, buff;
+  size_t copy;
+  struct data_block* block;
+
+  while (n > 0) {
+    buff = sector << SECTOR_SHIFT;
+    ix = buff >> dev->zb_block_shift;
+
+    offset = buff - (ix * dev->zb_block_size);
+    if (offset != 0) {
+      printk (KERN_WARNING "%s: bad aligned request\n", dev->zb_name);
+      return -EINVAL;
+    }
+
+    copy = min_t(size_t, dev->zb_block_size, n);
+
+    block = radix_tree_lookup(&dev->zb_data, ix);
+    if (check_zero(src, copy)) {
+      if (block) {
+        radix_tree_delete(&dev->zb_data, ix);
+        kfree(block);
+      }
+    } else {
+      if (!block)
+        block = alloc_block(dev, ix);
+      memcpy(block->data + offset, src, copy);
+    }
+
+    n -= copy;
+    src += copy;
+    sector += copy >> SECTOR_SHIFT;
+  }
+
+  return 0;
+}
+
+
+static int
+zerod_do_bvec(struct zb_device *dev, struct page *page,
+              uint32_t len, uint32_t off, int rw,
+              sector_t sector)
+/* Do a bvec request. */
+{
+  void *mem;
+  int err = 0;
+
+  mem = kmap(page);
+  if (rw == READ) {
+    down_read(&dev->zb_sem);
+    if (dev->zb_status == ZB_ACTIVE) {
+      err = copy_from_zerod(mem + off, dev, sector, len);
+    } else err = -ENXIO;
+    up_read(&dev->zb_sem);
+  } else {
+    down_write(&dev->zb_sem);
+    if (dev->zb_status == ZB_ACTIVE) {
+      err = copy_to_zerod(dev, mem + off, sector, len);
+    } else err = -ENXIO;
+    up_write(&dev->zb_sem);
+  }
+
+  kunmap(page);
+
+  return err;
+}
+
+static int
+zerod_make_request(struct request_queue *q, struct bio *bio)
+/* Callback function for request making.
+ *
+ * Tries to satisfy the request, without using a queue. */
+{
+  struct block_device *bdev = bio->bi_bdev;
+  struct zb_device *dev = bdev->bd_disk->private_data;
+  int rw;
+  struct bio_vec *bvec;
+  sector_t sector;
+  int i;
+  int err = -EIO;
+
+  down_read(&dev->zb_sem);
+  if (dev->zb_status == ZB_INACTIVE) {
+    err = -EPERM;
+    goto out;
+  } else if (dev->zb_status == ZB_REMOVED) {
+    err = -ENXIO;
+    goto out;
+  }
+
+  sector = bio->bi_sector;
+  if (sector + (bio->bi_size >> SECTOR_SHIFT) > get_capacity(bdev->bd_disk)) {
+    printk (KERN_WARNING "%s: request beyond device capacity\n", dev->zb_name);
+    up_read(&dev->zb_sem);
+    goto out;
+  }
+  up_read(&dev->zb_sem);
+
+  rw = bio_rw(bio);
+  if (rw == READA)
+    rw = READ;
+
+
+  if ( (bio->bi_vcnt == 0) && (bio->bi_rw & BIO_RW_BARRIER) ) {
+    /* Barrier request - pretend that everything is ok. */
+    err = 0;
+    goto out;
+  }
+
+  bio_for_each_segment(bvec, bio, i) {
+    uint32_t len = bvec->bv_len;
+    err = zerod_do_bvec(dev, bvec->bv_page, len,
+                             bvec->bv_offset, rw, sector);
+    if (err) {
+      break;
+    }
+    sector += len >> SECTOR_SHIFT;
+  }
+
+out:
+  bio_endio(bio, err);
+
+  return 0;
+}
+
+
+int
+find_shift(long block_size)
+/* Returns log_2(`block_size`) or -1 when `block_size` isn't in form of 2^k. */
+{
+  int ret = 0;
+  if (block_size < 0)
+    return -1;
+
+  while (block_size > 1) {
+    if (block_size % 2 == 1)
+      return -1;
+    ret += 1;
+    block_size >>= 1;
+  }
+  return ret;
+}
+
+int
+zerod_ioctl(struct block_device *bdev,
+     fmode_t mode,
+     unsigned int ioctl_num,  /* number and param for ioctl */
+     unsigned long ioctl_param)
+/* Device ioctl handler. */
+{
+  struct zero_bdev_config_arg config;
+  struct zb_device *dev = bdev->bd_disk->private_data;
+  int shift;
+
+  switch (ioctl_num) {
+    case ZERO_BDEV_CONFIGURE:
+      if (bdev->bd_openers > 1 || !down_write_trylock(&dev->zb_sem)) {
+        printk (KERN_INFO "%s: can't change configuration - device is busy\n",
+                dev->zb_name);
+        return -EBUSY;
+      }
+      if (dev->zb_status == ZB_REMOVED) {
+        return -ENXIO;
+      }
+
+      if (0 != copy_from_user(&config, (struct zero_bdev_config_arg __user *) ioctl_param,
+                              sizeof(struct zero_bdev_config_arg))) {
+        return -EIO;
+      }
+      shift = find_shift(config.zbc_block_size);
+      if (shift == -1) {
+        printk(KERN_WARNING "%s: %u is not a valid block size\n",
+               dev->zb_name, config.zbc_block_size);
+        return -EINVAL;
+      } else dev->zb_block_shift = shift;
+
+      dev->zb_status = ZB_ACTIVE;
+      dev->zb_block_size = config.zbc_block_size;
+      dev->zb_num_blocks = config.zbc_num_blocks;
+      blk_queue_logical_block_size(dev->zb_queue, dev->zb_block_size);
+      blk_queue_physical_block_size(dev->zb_queue, dev->zb_block_size);
+
+      set_blocksize(bdev, dev->zb_block_size);
+      set_capacity(dev->zb_gd,
+                   (dev->zb_num_blocks * dev->zb_block_size) >> SECTOR_SHIFT);
+      cleanup_tree(dev);
+
+      printk(KERN_INFO "%s: new configuration %ld (block size) %ld (num blocks)",
+             dev->zb_name, dev->zb_block_size, dev->zb_num_blocks);
+      up_write(&dev->zb_sem);
+
+      break;
+  }
+  return 0;
+}
+
+static struct block_device_operations zbd_ops = {
+    .owner = THIS_MODULE,
+    .ioctl = zerod_ioctl,
+};
+
+
+static int
+init_one(struct zb_device *dev, int i)
+/* Initializes a single zbd device. */
+{
+  sprintf(dev->zb_name, "zero_bdev%d", i);
+  dev->zb_major = register_blkdev(0, dev->zb_name);
+  if (dev->zb_major <= 0) {
+    printk (KERN_WARNING "%s: unable to get major number", dev->zb_name);
+    goto fail;
+  }
+
+  dev->zb_status = ZB_INACTIVE;
+  dev->zb_block_size = -1;
+  dev->zb_block_shift = -1;
+  dev->zb_num_blocks = -1;
+  dev->zb_minor = i;
+
+  INIT_RADIX_TREE(&dev->zb_data, GFP_ATOMIC);
+  init_rwsem(&dev->zb_sem);
+
+  /* requests queue */
+  dev->zb_queue = blk_alloc_queue(GFP_KERNEL);
+  if (!dev->zb_queue)
+    goto fail;
+  blk_queue_make_request(dev->zb_queue, zerod_make_request);
+  blk_queue_ordered(dev->zb_queue, QUEUE_ORDERED_TAG, NULL);
+  blk_queue_max_hw_sectors(dev->zb_queue, 1024);
+  blk_queue_bounce_limit(dev->zb_queue, BLK_BOUNCE_ANY);
+  dev->zb_queue->queuedata = dev;
+
+  /* disk structure */
+  dev->zb_gd = alloc_disk(1);
+  if (!dev->zb_gd)
+    goto fail_cleanup_queue;
+  dev->zb_gd->major = dev->zb_major;
+  dev->zb_gd->first_minor = 0;
+  dev->zb_gd->fops = &zbd_ops;
+  dev->zb_gd->private_data = dev;
+  dev->zb_gd->flags |= GENHD_FL_SUPPRESS_PARTITION_INFO;
+  sprintf(dev->zb_gd->disk_name, "%s", dev->zb_name);
+  dev->zb_gd->queue = dev->zb_queue;
+
+  add_disk(dev->zb_gd);
+
+  printk(KERN_INFO "%s: initizalized\n", dev->zb_name);
+  return 0;
+
+fail_cleanup_queue:
+  blk_cleanup_queue(dev->zb_queue);
+fail:
+  return -ENOMEM;
+}
+
+static int
+drop_one(struct zb_device *dev)
+/* Removes a zbd device. */
+{
+
+  down_write(&dev->zb_sem);
+
+  dev->zb_status = ZB_REMOVED;
+  del_gendisk(dev->zb_gd);
+  put_disk(dev->zb_gd);
+  if (dev->zb_queue != NULL)
+    blk_cleanup_queue(dev->zb_queue);
+  cleanup_tree(dev);
+  unregister_blkdev(dev->zb_major, dev->zb_name);
+
+  up_write(&dev->zb_sem);
+
+  return 0;
+}
+
+static void
+exit_from(int i);
+
+static int
+__init zerod_init(void)
+/* Module initialization callback. */
+{
+  int i;
+
+  if (!num_devs) {
+    num_devs = CONFIG_ZERO_BDEV_COUNT;
+  }
+
+  devices = kzalloc(sizeof(struct zb_device) * num_devs, GFP_KERNEL);
+  if (devices == NULL)
+    goto out;
+
+  for (i = 0; i < num_devs; i++) {
+    if(init_one(&devices[i], i) < 0)
+      goto cleanup;
+  }
+
+  printk(KERN_INFO "zero_bdev: module loaded\n");
+  return 0;
+
+cleanup:
+  exit_from(i - 1);
+out:
+  return -ENOMEM;
+}
+
+static void
+__exit zerod_exit(void)
+/* Module removal callback. */
+{
+  printk(KERN_INFO "zero_bdev: destroying %d device(s)\n", num_devs);
+  exit_from(num_devs - 1);
+}
+
+static void
+exit_from(int i)
+/* Removes devices starting from "zbd`i`" down to "zbd0". */
+{
+  for (; i >= 0; i--) {
+    printk(KERN_INFO "%s: dropping\n", devices[i].zb_name);
+    drop_one(&devices[i]);
+  }
+  kfree(devices);
+  printk(KERN_INFO "zero_bdev: module unloaded\n");
+}
+
+module_init(zerod_init);
+module_exit(zerod_exit);
diff --git a/fs/ext2/ext2.h b/fs/ext2/ext2.h
index 0b038e4..446bb10 100644
--- a/fs/ext2/ext2.h
+++ b/fs/ext2/ext2.h
@@ -60,6 +60,12 @@ struct ext2_inode_info {
 	struct list_head i_orphan;	/* unlinked but open inodes */
 };
 
+struct ext2_fake_b_alloc_arg {
+  uint32_t efba_size;
+  uint32_t efba_pad_; //unused
+  uint64_t efba_off;
+};
+
 /*
  * Inode dynamic state flags
  */
diff --git a/fs/ext2/ioctl.c b/fs/ext2/ioctl.c
index e743130..ff08cfd 100644
--- a/fs/ext2/ioctl.c
+++ b/fs/ext2/ioctl.c
@@ -13,10 +13,10 @@
 #include <linux/sched.h>
 #include <linux/compat.h>
 #include <linux/mount.h>
+#include <linux/buffer_head.h>
 #include <asm/current.h>
 #include <asm/uaccess.h>
 
-
 long ext2_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 {
 	struct inode *inode = filp->f_dentry->d_inode;
@@ -28,6 +28,61 @@ long ext2_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 	ext2_debug ("cmd = %u, arg = %lu\n", cmd, arg);
 
 	switch (cmd) {
+  case EXT2_FAKE_B_ALLOC:
+    /* Fake allocation for ext2 filesystem.
+     *
+     * Tries to allocate all blocks necessary to satisfy request using a 
+     * `ext2_get_block()` function. Than set the metadata.
+     *
+     * I think that may be a problem, when there're not enough blocks for
+     * allocation on disc, since `ext2_get_block()` doesn't seems to
+     * inform about such case. But I really don't have time to made it
+     * first-class :( */
+    {
+      struct ext2_fake_b_alloc_arg config;
+      struct buffer_head bh_result;
+      sector_t iblock, off;
+      int ret = 0;
+
+      ret = copy_from_user(&config, (struct ext2_fake_b_alloc_arg __user *)arg,
+                           sizeof(struct ext2_fake_b_alloc_arg));
+      if (ret != 0) {
+        printk (KERN_DEBUG "can't copy from user");
+        return -EIO;
+      } else ret = 0;
+
+      /* Allocate blocks. */
+      off = config.efba_off;
+      iblock = config.efba_off >> inode->i_blkbits;
+      while ((iblock << inode->i_blkbits) <
+                  (config.efba_off + config.efba_size)) {
+        /* Can't say, that I'm sure what I'm doing o.O */
+        memset(&bh_result, 0, sizeof(struct ext2_fake_b_alloc_arg));
+        ret = ext2_get_block(inode, iblock, &bh_result, 1);
+        if (ret < 0) {
+          printk (KERN_DEBUG "get_block_error %d, escaping", ret);
+          break;
+        }
+        iblock++;
+      }
+
+      /* Set metadata */
+      write_lock(&EXT2_I(inode)->i_meta_lock);
+      if (ret == 0) {
+        inode->i_size = max_t(loff_t, inode->i_size,
+                            config.efba_off + config.efba_size);
+      } else if(iblock != config.efba_off >> inode->i_blkbits) {
+        /* Partially allocated, size must be fixed.           *
+         * But `i_blocks` should containt actual information. */
+        inode->i_size = inode->i_blocks << inode->i_blkbits;
+      }
+      inode->i_mtime = inode->i_atime = CURRENT_TIME_SEC;
+      inode->i_version++;
+      write_unlock(&EXT2_I(inode)->i_meta_lock);
+
+      return ret;
+    }
+
 	case EXT2_IOC_GETFLAGS:
 		ext2_get_inode_flags(ei);
 		flags = ei->i_flags & EXT2_FL_USER_VISIBLE;
diff --git a/include/linux/ext2_fs.h b/include/linux/ext2_fs.h
index 2dfa707..0b0c95e 100644
--- a/include/linux/ext2_fs.h
+++ b/include/linux/ext2_fs.h
@@ -227,6 +227,7 @@ static inline __u32 ext2_mask_flags(umode_t mode, __u32 flags)
 #define	EXT2_IOC_SETVERSION		FS_IOC_SETVERSION
 #define	EXT2_IOC_GETRSVSZ		_IOR('f', 5, long)
 #define	EXT2_IOC_SETRSVSZ		_IOW('f', 6, long)
+#define EXT2_FAKE_B_ALLOC   		0x66660666
 
 /*
  * ioctl commands in 32 bit emulation
-- 
1.7.7.6

